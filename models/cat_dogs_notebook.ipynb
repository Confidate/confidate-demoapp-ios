{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/train.zip"
      ],
      "metadata": {
        "id": "gryHrNH3Iyu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation"
      ],
      "metadata": {
        "id": "1ovPM6Hlvkig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/train'"
      ],
      "metadata": {
        "id": "yaUE5rTyrLnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(28, 28),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training',\n",
        "    color_mode='rgb'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(28, 28),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation',\n",
        "    color_mode='rgb'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ezmv4X3osGv",
        "outputId": "69eab0d9-9966-4c13-a138-a37cbb1c9692"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 164 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "inputs = Input(shape=(28, 28, 3))\n",
        "x = MaxPooling2D(pool_size=(2, 2))(inputs)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dense(2, activation='softmax')(x)  # Используем 2 выхода для 2 классов\n",
        "\n",
        "model = Model(inputs, x)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "4aqGlz86osBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=50\n",
        ")"
      ],
      "metadata": {
        "id": "JUdG7K5ksgVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
        "print(f'Validation loss: {val_loss}, validation accuracy: {val_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOhhTz2VsgTJ",
        "outputId": "8de31f70-8477-480e-b29a-1ec840038684"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6758 - accuracy: 0.6250\n",
            "Validation loss: 0.6758458018302917, validation accuracy: 0.625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_rgb.h5')"
      ],
      "metadata": {
        "id": "GpX2ruX0sgQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I4RTSPGg2Oo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "\n",
        "test_image_path = '/content/test3.jpg'\n",
        "img = load_img(test_image_path, target_size=(28, 28), color_mode='grayscale')  # Масштабирование и преобразование в ЧБ\n",
        "img_array = img_to_array(img)  # Преобразование изображения в массив\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Добавление batch размерности\n",
        "img_array /= 255.0  # Нормализация\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "predicted_class_index = np.argmax(predictions, axis=1)[0]  # Получение индекса наиболее вероятного класса\n",
        "\n",
        "class_names = ['cat','dog']  # Убедитесь, что порядок соответствует порядку классов в вашей модели\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "\n",
        "print(f\"Predicted class: {predicted_class_name}\")"
      ],
      "metadata": {
        "id": "pXEYTX-lsgOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87868eb6-3dd3-4211-c4c7-051a506e40fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 13ms/step\n",
            "Predicted class: dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U coremltools\n"
      ],
      "metadata": {
        "id": "H2NQf2rOsgLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import coremltools as ct\n",
        "\n",
        "\n",
        "\n",
        "image_input = ct.ImageType(shape=(1, 28, 28, 3))\n",
        "\n",
        "\n",
        "\n",
        "coreml_model = ct.convert(\n",
        "    model,\n",
        "    inputs=[image_input],\n",
        "    classifier_config=ct.ClassifierConfig(['cat', 'dog']),\n",
        "    minimum_deployment_target=ct.target.iOS13\n",
        ")\n",
        "\n",
        "\n",
        "coreml_model.save('model_cat_dog_rgb.mlmodel')\n"
      ],
      "metadata": {
        "id": "6YUCjUUlor8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b25bf68-0090-4f17-a9f7-57cd4419e7ed"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running TensorFlow Graph Passes: 100%|██████████| 6/6 [00:00<00:00, 20.06 passes/s]\n",
            "Converting TF Frontend ==> MIL Ops: 100%|██████████| 15/15 [00:00<00:00, 2839.62 ops/s]\n",
            "Running MIL frontend_tensorflow2 pipeline: 100%|██████████| 7/7 [00:00<00:00, 5303.49 passes/s]\n",
            "Running MIL default pipeline: 100%|██████████| 69/69 [00:00<00:00, 2187.56 passes/s]\n",
            "Running MIL backend_neuralnetwork pipeline: 100%|██████████| 9/9 [00:00<00:00, 6800.35 passes/s]\n",
            "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 19/19 [00:00<00:00, 3871.92 ops/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "ly4ZGex0N7_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/vitalik_resized_rgb.jpeg\"\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "if image is None:\n",
        "    print(\"Не удалось загрузить изображение\")\n",
        "else:\n",
        "    cv2_imshow(image)\n",
        "\n",
        "    height, width, channels = image.shape\n",
        "    print(\"Ширина изображения:\", width)\n",
        "    print(\"Высота изображения:\", height)\n",
        "    print(\"Количество каналов изображения:\", channels)\n"
      ],
      "metadata": {
        "id": "S8TY2bsZor5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7TJSS3dgor3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m7oruJaBorz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SCDjaJ5XorxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c90XZ96Joruc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_RYcts7orrq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}